---
title: "1st Global coordinated observation of the Youtube algorithm"
subtitle: "Only by compare how AI mistreat you and others, we can grasp how this is a collective issue"
draft: false
date: 2020-03-01T10:26:08Z

og_title: "1st Global collaborative analysis of Youtube Algorithm"
og_type: "website"
og_image: "http://youtube.tracking.exposed/images/compare.jpeg"
og_url: "https://youtube.tracking.exposed/wetest/1"
og_description: "This is the first worldwide test of the Youtube algorithm; on Sunday March 15th, with a browser extension, we'll see how YT personalizes the customer experience"

extraCSS: "/css/wetest.css"
---

<script src="/js/collaborative-tests.js"></script>

<div class="container col-12 justify-content-center">
  <h1 style="text-align:center;">Experiment — 15 of March 2020 — in
    <span class="project-color"> <span id="demo"></span> </span>
   </h1>
</div>

<div class="container row">
  <img width="48%" class="align-right imgtile" src="/images/wetest-youtrust.jpg" />
  <img width="48%" class="align-left imgtile" src="/images/wetest-how.jpg" />
</div>

<br>
{{<colorblock text="a 10 minutes experiment where every contribution matters.">}}
<br>

<div class="container col-12 justify-content-center">
  <h2 class="project-color">FIRST ― To save evidence of personalization join us: </h2>
  {{<yt-extension >}}
</div>

{{<colorblock >}}
<br>

<div class="container col-12 justify-content-center">
  <h2 class="project-color">SECOND ― Following the links, the order matter!</h2>

  <small>The links will be declared few hours before the test start!</small>
  <div class="test-steps links--disabled">
    <ol>
      <li>
        Open <a href="https://www.youtube.com" target="_blank">YouTube Homepage</a>.
      </li>
      <li>
        Watch The first video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Watch The second video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Watch The third video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Watch The fourth video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Open againg <a href="https://www.youtube.com" target="_blank">YouTube Homepage </a> 
      </li>
    </ol>
    <small>Why have we <a href="/wetest/announcement-1#on-experiment-design">organized the test this way</a>?</small>
    <br>
    <br>
  </div>

</div> <!-- container -->

{{<colorblock >}}

<div class="container col-12 justify-content-center">
  <br>
  <h2 class="project-color">THIRD ― Compare, analyze, understand</h2>
  <br>

  <div class="row enlarged">
    <div class="col-4">
      We'll release the data, properly anonymized, for public analysis, 
      <a href="/wetest/announcement-1">Here you'll find releases and updates</a>.
      <br>
      <br>
      If you produce findings or visualization, we'll be glad to include yours, so please <a href="https://chat.securitywithoutborders.org/community/channels/trackingexposed">reach out in our mattermost chat</a>.
    </div>
    <div class="col-4">
      In the meanwhile, you can run comparison on your own. TODO links
    </div>
    <div class="col-4">
      link to documentation, link to analysis tools, etc etc
    </div>
  </div> 

</div> <!-- container -->

<br>
{{<colorblock >}}

<div class="container col-12 justify-content-center">
  <br>
  <h2 class="project-color">EXTRA ― Know more, on us, on this test design and what should happen next</h2>
  <br>
  <div class="row enlarged">
    <div class="col-6">
      <h3>Design logic</h3>
      <p>Testing a personalization algorithm isn't quick and straightforward, as it can seem. The researcher has to define a methodology. This method gives different values to the collected samples because they are only useful to test the assumptions initially made. 
        <br>
        We collect here the many experiences we had regardless of the various approach we tried so far. 
        <br>
        <br>
        Because wetest wants to be a collaborative experiment, it is smart to develop initial findings without assuming any past research. We have them, but we'll start with a few concise research questions. 
        <br>
        Inevitability these question would be closer to the technical side, and not to the political impact. The initial phase we face is perfect for developing tools and practices. 
        <br>
        Tracking.exposed goals aren't merely to produce reports, articles, or researches. Yes, we do it; it has been part of our training experience. Algorithm accountability can't be revolutionary if accessible only to data analyst and data protection authority. A bit of knowledge on platform influence, or algorithm literacy, should be in the modern background education, and we want to play with it. 
      </p>

    </div>
    <div class="col-6">
      <img class="imgtile" width="90%" src="/images/wetest-youralgo.jpg" />
      <smaller style="font-size:0.6em;">This is our 
        <a href="https://tracking.exposed/manifesto">Manifesto </a>, or checkout the 
        <a href="https://pornhub.tracking.exposed/potest/final-1">collaborative PornHub analysis</a>, and
        <a href="/preview">use ytTREX</a>.
      </smaller>
      <br>
      <h3>This test</h3>
      <p>
        When we see articles such as "" quoting "", it is clear we've a language issue. maybe in English language, for the US audience and US politician, Youtube investment might guarantee a quality in content curaction high enough to avoid fines, but would be that true in another language? 
        <br>
        The exploitative business model of surveillance capitalism can't easily scale when the succes metric is the _removal of content troublesome for a precise culture_ because investing in content moderator trained and balanced in every culture in the world seems unfeasable due to high costs.
        <br>
        This first experiment concentrate effort in watching four videos chosen by us, on the same broad topic (covid19), in the four most spread langagues in the world.
        <br>
        Do you remember, companies take a bunch of random users and experiment on them? We'll do precisely the opposition: a distributed crowd of random individuals. Someone with a clean, freshly installed browser, someone else with their Google account logged. Watching a few videos, to collectively watch how personalized is the experience the company decide for us.
        <br>
      </p>
    </div>
  </div> 

  <h3>
    We want to apply the most scientific, open, distributed approach we can aim for
  </h3>
  <p>
    <b>
      Diversity is the key
    </b>, but how exactly?
    <br>
    <br>
    Personalization algorithms, content curation, and targeted experiences are unique for each of us. 
    <br>
    Winning the fight for algorithmic independence (when you retain agency and control on the prioritization filter know as recommendation system), make sense if most of us reach that point. A minority of techno elite, literate enough to fact-check and has a bunch of tricks to find the right information, would only reinforce inequity in the information age. Diversity is the key because we collectively should understand how other people are perceiving the public discourse. 
    <br>
    Recommendation algorithm is public policy, they should be subject to public scrutiny, impact all of us, and companies trim them to regulate fringe behaviors. Just in 2020, the goal is not a better society but a fluid business flow in the monopolist's hand.
    <br>
    Algorithm analysis might be a purely technical effort in a fully known system. But the platform we're operating on (Facebook, youtube, amazon) mixes social constructs with their technology, and implicitly, the limited form of algorithm analysis we can perform via passive observation, inherit complexities typical of political analysis.
    <br>
    <br>
    Now, with wetest#1, <b>we begin with the technical analysis</b>. To be crystal clear, we can't yet aim to research questions such as "do youtube radicalize or not people?" or "are videos with blonde white women prioritized against other demographics? It is true in any region?". We want to coordinate tests with these politically meaningful topics, but we can't yet, they aren't low hanging fruits. Releasing approximative analysis would be detrimental for algorithm literacy and platform accountability. Let's build this community with academics and digital rights defender. 
    <br>
    If you have an idea, propose your experiment by
    <a href="https://github.com/tracking-exposed/youtube.tracking.exposed/issues/new?assignees=&labels=research+question&template=research-question-proposal.md&title=%3CRQ%3E" target=_blank>opening this formatted GitHub issue</a>
    , and please consider:
    <ol>
      <li>we should start to measure technical conditions, and be confident in testing such variables.</li>
      <li>read other issues marked in the same way; this might help to understand which limits this test has.</li>
      <li>research questions should come from the community: concerned citizen, seasoned professional expert, the method to submit is to open a GitHub issue in our repository, and if you expect</li>
    </ol>
  </p>

</div> <!-- container -->

<script>
  $(document).ready(function() {
    countdown(new Date("Mar 15, 2020 00:00:01"), "demo");
  });
</script>